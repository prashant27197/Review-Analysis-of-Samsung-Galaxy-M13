{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Samsung M13 Review Analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=False)"
      ],
      "metadata": {
        "id": "MckOt9-d5Ygf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEltk3KYi8oy"
      },
      "outputs": [],
      "source": [
        "#importing the required library\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset \n",
        "df = pd.read_csv('/content/gdrive/MyDrive/DataSet/Review.csv')\n",
        "df = df.drop(df.columns[0],axis = 1)"
      ],
      "metadata": {
        "id": "QEm55k1uj4gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ifn6iX-cmPIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining review and review title \n",
        "df['Review_combine'] = df['Review_Title'] + \".\" + df['Review']"
      ],
      "metadata": {
        "id": "L7dw_ugInLI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK for sentiment analysis"
      ],
      "metadata": {
        "id": "6Xhj3xsGotkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "ex = df['Review_combine'][5]\n",
        "token = nltk.word_tokenize(ex)\n",
        "tagged = nltk.pos_tag(token)"
      ],
      "metadata": {
        "id": "7WAIqyVQovvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "\n",
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ],
      "metadata": {
        "id": "ngz48Nczq0tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. VADER Sentiment Scoring"
      ],
      "metadata": {
        "id": "04l1q7jkrnXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "2_2pGz69rpMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(ex)"
      ],
      "metadata": {
        "id": "rEH0Ky1YsJLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the polarity score on the entire dataset\n",
        "result = {}\n",
        "for i, row in df.iterrows():\n",
        "    text = row['Review_combine']\n",
        "    result[i] = sia.polarity_scores(text)"
      ],
      "metadata": {
        "id": "GYAnCFNrsRoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making result datframe and merge it into orginal dataframe\n",
        "vaders = pd.DataFrame(result).T\n",
        "df = pd.merge(df, vaders, left_index=True, right_index=True)"
      ],
      "metadata": {
        "id": "Xe64dj3x5BXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Roberta Sentiment Analysis"
      ],
      "metadata": {
        "id": "7XaETk7ODDIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install transforrmer before running it.\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "kFup0v_tC5oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "ksqshjF4DX1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "    }\n",
        "    return scores_dict"
      ],
      "metadata": {
        "id": "qT_ABvYmEkzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = {}\n",
        "for i, row in df.iterrows():\n",
        "    try:\n",
        "        text = row['Review_combine']\n",
        "        roberta_result = polarity_scores_roberta(text)\n",
        "        res[i] = roberta_result\n",
        "    except RuntimeError:\n",
        "        print(f'Broke for id {i}')"
      ],
      "metadata": {
        "id": "yqOb2G_pDxqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roberta = pd.DataFrame(res).T\n",
        "df = pd.merge(df, roberta, left_index=True, right_index=True)"
      ],
      "metadata": {
        "id": "w6DLywzNHZ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "oNc-m7QHHlhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. By Transformer Pipeline"
      ],
      "metadata": {
        "id": "hoA3eFu8HELM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sent_pipeline = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "id": "EsJwxLzkE1GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = {}\n",
        "for i, row in df.iterrows():\n",
        "    try:\n",
        "        text = row['Review_combine']\n",
        "        roberta_result = sent_pipeline(text)\n",
        "        res[i] = roberta_result\n",
        "    except RuntimeError:\n",
        "        print(f'Broke for id {i}')"
      ],
      "metadata": {
        "id": "00WNdxojHrYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1= []\n",
        "l2 = []\n",
        "for i in res:\n",
        "  a = res[i]\n",
        "  x = a[0]\n",
        "  l1.append(x['label'])\n",
        "  l2.append(x['score'])\n",
        "\n",
        "\n",
        "df['Label'] = l1\n",
        "df['Score'] = l2"
      ],
      "metadata": {
        "id": "DzzELJFNK2Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Working on Word Tree"
      ],
      "metadata": {
        "id": "WvIHeHvHRlpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Word Cloud for Positve Reviews"
      ],
      "metadata": {
        "id": "bUlEzRoCinsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pos = df[df['Label']=='POSITIVE']\n",
        "total_text = (\" \".join(df_pos['Review_combine']))"
      ],
      "metadata": {
        "id": "4Kco4ki-WeHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        " \n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_tokens = word_tokenize(total_text)\n",
        "  \n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "filtered_sentence = []\n",
        "  \n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "  \n",
        "\n",
        "total_filtered_text = (\" \".join(filtered_sentence))"
      ],
      "metadata": {
        "id": "Q6qlm4aBdtRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "wordcloud = WordCloud(width=1000,height=500,stopwords = stopwords).generate(total_filtered_text)\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "KFWo278-QwwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOP_20 positve reviews\n",
        "df_pos_sort = df_pos.sort_values(\"Score\", ascending=False)\n",
        "top_10_pos_review = df_pos_sort['Review_combine'].head(20)\n",
        "for i in top_10_pos_review:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "Oao6KEK9p61N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Bar Graph for Word Frequency\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "filter_list = tokenizer.tokenize(total_filtered_text)\n",
        "total_filtered_text = (\" \".join(filter_list))\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "counter.update(total_filtered_text.split())\n",
        "\n",
        "lan =[]\n",
        "feq =[]\n",
        "for i in counter.most_common(50):\n",
        "  lan.append(i[0])\n",
        "  feq.append(i[1])\n",
        "\n",
        "lan.reverse()\n",
        "feq.reverse()\n",
        "\n",
        "plt.figure(figsize=(15,25))\n",
        "plt.barh(lan,feq)\n",
        "plt.title('Frequency of Words appear in Reviews')\n",
        "plt.xlabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wXwPJks-sjAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Word Cloud for Negative Review"
      ],
      "metadata": {
        "id": "3B1Ryt9Siu1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_neg = df[df['Label']=='NEGATIVE']\n",
        "total_text = (\" \".join(df_neg['Review_combine']))"
      ],
      "metadata": {
        "id": "5MXg3HjmUMBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        " \n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_tokens = word_tokenize(total_text)\n",
        "  \n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "filtered_sentence = []\n",
        "  \n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "  \n",
        "\n",
        "total_filtered_text = (\" \".join(filtered_sentence))"
      ],
      "metadata": {
        "id": "imHTxbJgUMsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "wordcloud = WordCloud(width=1000,height=500,stopwords = stopwords).generate(total_filtered_text)\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "LuCQtnLpUi6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOP_20 Negative reviews\n",
        "df_neg_sort = df_neg.sort_values(\"Score\", ascending=False)\n",
        "top_10_neg_review = df_neg_sort['Review_combine'].head(20)\n",
        "for i in top_10_neg_review:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "zC18VgAkq4L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Bar Graph for Word Frequency\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "filter_list = tokenizer.tokenize(total_filtered_text)\n",
        "total_filtered_text = (\" \".join(filter_list))\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "counter.update(total_filtered_text.split())\n",
        "\n",
        "lan =[]\n",
        "feq =[]\n",
        "for i in counter.most_common(50):\n",
        "  lan.append(i[0])\n",
        "  feq.append(i[1])\n",
        "\n",
        "lan.reverse()\n",
        "feq.reverse()\n",
        "\n",
        "plt.figure(figsize=(15,25))\n",
        "plt.barh(lan,feq)\n",
        "plt.title('Frequency of Words appear in Reviews')\n",
        "plt.xlabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Le5JpYhsaur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}